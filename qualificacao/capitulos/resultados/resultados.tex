\mychapter{Resultados parciais}
\label{cap:resultados}

% Dados para as simulações da qualificação
% Tempo de simulação de 105 segundos (totalizando 00:01:45)
% Valores utilizados => Observar folha


% Montar tabela com os valores dos parametros alterados para o treinamento e
% para a validação das falhas. Exemplo:
% 
% FAVK => km_treinamento = (0.7 a 1.1)*km_original (PRBS)
%         km_validacao = (0.75 a 1.05)*km_original (PRBS) => nao precisa
%                                                            especificar o valor
%                                                            exato, mas dizer
%                                                            que estava dentro
%                                                            da faixa do
%                                                            treinamento
%         km_resultado = (0.75)*km_original (Fixo)
%
% FSeDG => ganho_treinamento = (1 +- 0.2)*ganho_original (PRBS)
%          ganho_validacao = (1 +- 0.15)*ganho_original (PRBS)
%          ganho_resultado = 0.8*ganho_original (fixo)
%


% Mostrar que foram feitos 3 conjuntos de validacao e depois foram escolhidas as
% melhores redes => Mostrar tabelas com Falso positivo e falso negativo


% Quando for falar sobre o número de regressores escolhidos => Dizer que
% considere que os regressores estão representados internamente ao "sistema de
% identificação" e ao "sistema de DDF" na figura da composição do sistema (final
% do cap:sistema)

\begin{comment}
Neste capítulo será realizada uma análise comparativa dos resultados obtidos nas
duas propostas do sistema de DDF. Ao final, do capítulo a melhor estrutura será
escolhida para que seja feita uma análise mais detalhada dos resultados.
\end{comment}

Neste capítulo serão analisados os resultados parciais obtidos a partir da
implementação da segunda proposta do sistema de DDF. Para isso, em um primeiro
momento será mostrado como se deu a coleta dos dados de treinamento e validação
das redes especialistas e em seguida será feita uma comparação de desempenho. Ao
final do capítulo as melhores estruturas serão selecionadas para que se realize
uma análise um pouco mais detalhada acerca da detecção das falhas.

% ------------------------------------------------------------------------------
\section{Coleta dos dados}
Tanto para o processo de identificação quanto para o processo de detecção, o
primeiro passo a ser dado é a obtenção das amostras experimentais para o
treinamento supervisionado das redes neurais de inferência e de detecção.

Dessa maneira, realizou-se a coleta dos dados a partir da estimulação do sistema
simulado através da aplicação de sinais binários pseudo aleatórios ({Pseudo
Random Binary Signals} -- PRBS) à referência de cada um dos tanques e aos
parâmetros do sistema que simulam as falhas. Para a identificação, a faixa de
valores aplicados se deu do nível mínimo (zero) ao máximo (trinta). Já para a
detecção das falhas, os valores foram aplicados conforme Tab.
\ref{tab:valores_treinamento}. Nessa tabela os valores mínimos e máximos são
multiplicados pelo valor padrão e aplicados ao modelo. A última coluna mostra
qual será a representatividade da mudança dos valores.

\begin{table}[htb]
\caption{Valores aplicados para o treinamento das redes neurais de detecção.}
\label{tab:valores_treinamento}
\vspace{0.25cm}
\centering
\begin{threeparttable}
\begin{tabular}{|c|c|c|c|c|}
\hline
{\bf Falha} & {\bf Valor padrão} & {\bf Mínimo} & {\bf Máximo} & 
{\bf Representatividade}\\
\hline
\hline
FSeDG & 0,16\tnote{$*$} & 
0,8 & 1,2 & Até $\pm 6$ cm\\
\hline
FSeDO & 1,0 & -3,0 & 3,0 & Até $\pm 3$ cm\\
\hline
FSeSR & 1,0 & -0,03 & 0,03 & Até $\pm 9$ cm\\
\hline
FSeQ & 1,0 & 0,0 & 0,0 & -- \\
\hline
\hline
FADG & 1,0 & 0,8 & 1,0 & Até -3 Volts\\
\hline
FADO & 1,0 & -1,0 & 0,0 & Até -1 Volts\\
\hline
FASR & 1,0 & -0,03 & 0,03 & Até $\pm 0,45$ Volts\\
\hline
FAVK & $K_m$ & 0,7 & 1,1 & --\\
\hline
FAQ & 1,0 & 0,0 & 0,0 & --\\
\hline
\hline
FSiVzT & $a_{i_{\text{\tiny MED}}}$ & 
0,25 & 0,75 & 25 a 75\% de $a_{i_{\text{\tiny MED}}}$\\
\hline
FSiVrOS & $a_{i_{\text{\tiny MED}}}$ & 
0,75 & 1,25 & $\pm 25\%$ de $a_{i_{\text{\tiny MED}}}$\\
\hline
FSiVrGMP & 5,0\tnote{$*$} & 
0,8 & 1,0 & Até -3 Volts\\
\hline
FSiEOS & $a_{i_{\text{\tiny MED}}}$ & 
0,0 & 0,5 & --\\
\hline
\end{tabular}
\begin{tablenotes}
\item [$*$] Estabelecido pelo manual do fabricante.
\end{tablenotes}
\end{threeparttable}
\end{table}

Perceba que nas falhas dos atuadores, as tensões a serem aplicadas podem vir a
danificar a bomba. Por esse motivo não seria viável obter as amostras do
processo real, mas sim a partir de uma simulação.

Os sinais pseudo aleatórios gerados se mantiveram dentro dos limites
estabelecidos durante todo o intervalo de tempo da simulação. Para o processo de
identificação foram obtidas 6000 (seis mil) amostras, equivalentes à 10 (dez)
minutos de simulação. Já para a detecção o processo foi simulado durante 20
(vinte) minutos, o que correspondeu a obtenção de 12000 (doze mil) amostras.

De posse dos valores obtidos, iniciou-se a fase de treinamento das RNAs. Todas
as redes foram treinadas de modo {\it offline} com o {\it toolbox} de redes
neurais do {\it software} matemático Matlab\reg\ utilizando o algoritmo LMA. Ao
final de cada etapa de treinamento as redes eram submetidas à testes de
validação para que se fosse possível avaliar a capacidade de generalização.

% ------------------------------------------------------------------------------
\section{Análise das RNAs}
Para que se fossem estabelecidos critérios avaliativos significantes, ou seja,
para que existisse um número representativo, diversas redes neurais foram
treinadas com diferentes configurações do número de neurônios na camada oculta e
da ordem do modelo. O número de redes treinadas corresponde aquele especificado
no final da Tab. \ref{tab:treinamentos}. 

\begin{table}[htb]
\centering
\caption[Número de redes neurais treinadas]{Número de redes neurais treinadas de
acordo com a ordem do modelo e o número de neurônios na camada oculta.}
\label{tab:treinamentos}
\vspace{0.25cm}
\begin{tabular}{|c|c|c|c|c|}
\hline
% Linha 1
\multirow{2}{*}{\bf Proposta} & 
\multirow{2}{*}{\bf Ordem} & 
{\bf Neurônios na} & 
{\bf Número de} & 
\multirow{2}{*}{\bf Total}\\
% Linha 2
& & {\bf camada oculta} & {\bf redes treinadas} &\\
\hline
\hline
\multicolumn{5}{|l|}{{\bf Identificação}}\\
\hline
\multirow{3}{*}{1} & 2 & 6/8/10 & \multirow{3}{*}{6} & \multirow{3}{*}{54}\\
\cline{2-3}
& 3 & 8/12/16 & &\\
\cline{2-3}
& 4 & 10/16/22 & &\\
\hline
\multirow{3}{*}{2} & 2 & 2/4/6 -- 6/8/10 & 
\multirow{3}{*}{6} & \multirow{3}{*}{108}\\
\cline{2-3}
& 3 & 4/6/8 -- 8/12/16 & & \\
\cline{2-3}
& 4 & 6/8/10 -- 10/16/22 & & \\
\hline
\multicolumn{5}{|l|}{{\bf Detecção}}\\
\hline
\multirow{3}{*}{2} & 2 & 8/12/16 & 
\multirow{3}{*}{6/falha} &
\multirow{3}{*}{702}\\
\cline{2-3}
& 3 & 14/18/22 & &\\
\cline{2-3}
& 4 & 20/24/28 & &\\
\hline
\hline
\multicolumn{4}{|r|}{{\bf Total}} & 864\\
\hline
\end{tabular}
\end{table}

Na primeira proposta de identificação, de segunda ordem, foram treinadas 6
(seis) redes neurais cada vez que o número de neurônios na camada oculta era
alterado. Ou seja, para cada ordem eram treinadas 18 (dezoito) redes neurais.
Como foram testadas três ordens distintas em cada proposta, tem-se um total de
54 (cinquenta e quatro) redes para a primeira proposta.

Observa-se entretanto que, na segunda proposta de identificação existiam duas
redes neurais a serem treinadas em cada etapa de treinamento, conforme Fig.
\ref{fig:ident_proposta_2}, e que a segunda proposta de detecção considera-se um
conjunto de 13 (treze) redes especialistas, sendo uma para cada falha, conforme
Fig. \ref{fig:detec_prop_2}. Em virtude desses aspectos, o número de redes
treinadas dobra da primeira para a segunda proposta de identificação e é
multiplicado por um fator de treze para a segunda proposta de detecção.

% ------------------------------------------------------------------------------
\section{Melhores redes}
Diante do grande número de redes neurais a serem analisadas, foi necessário
estabelecer algum tipo de critério avaliativo para que as melhores redes fossem
selecionadas. Para as propostas de detecção utilizou-se o EMQ sobre os valores
de saída $\widehat{L_1}$ e $\widehat{L_2}$, enquanto que para as redes de
detecção fez-se uso do número de erros de tipo I e erros de tipo II.  O EMQ e o
número de erros de tipo I e II de cada rede foram obtidos a partir da média dos
valores de três validações distintas.

% ------------------------------------------------------------------------------
\subsection{Redes para identificação}
Utilizando o EMQ estabelecido pela Eq. \ref{eq:emq}, foram obtidos os resultados
exibidos pela Tab. \ref{tab:melhores_rnas_ident}.

\begin{table}[htb]
\centering
\caption{Melhores redes treinadas para a identificação do modelo.}
\label{tab:melhores_rnas_ident}
\vspace{0.25cm}
\begin{threeparttable}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
% Linha 1
{\bf Proposta} & 
{\bf Ordem} & 
{\bf NCO\tnote{$*$}} & 
{\bf Treinamento} &
{\bf EMQ $\mathbf{L_1}$} & 
{\bf EMQ $\mathbf{L_2}$} & 
{\bf EMQ}\\
\hline
\hline
\multirow{3}{*}{1} &
\cellcolor[gray]{0.9} 2 &
\cellcolor[gray]{0.9} 8 &
\cellcolor[gray]{0.9}2 &
\cellcolor[gray]{0.9} 4,39e-7 &
\cellcolor[gray]{0.9} 3,29e-6 &
\cellcolor[gray]{0.9} 3,73e-6\\
\cline{2-7}
&3 & 12 & 5 & 1,38e-5 & 1,46e-5 & 2,84e-5\\
\cline{2-7}
&4 & 22 & 4 & 1,40e-6 & 2,60e-6 & 4,01e-6\\
\hline
\multirow{3}{*}{2} & 2 & 2 -- 6 & 2 & 5,06e-6 & 7,26e-6 & 1,23e-5\\
\cline{2-7}
& 3 & 6 -- 12 & 1 & 5,48e-6 & 1,81e-7 & 5,66e-6\\
\cline{2-7}
& 4 & 10 -- 22 & 3 & 5,12e-6 & 9,46e-6 & 1,45e-5\\
\hline
\end{tabular}
\begin{tablenotes}
\item [$*$] Número de neurônios na camada oculta.
\end{tablenotes}
\end{threeparttable}
\end{table}

Assim, a melhor rede de identificação, escolhida para estimar os valores de
$L_1$ e $L_2$, foi a rede de segunda ordem, com oito neurônios na camada oculta,
obtida no segundo treinamento. Essa rede, cuja soma dos EMQs foi de $3,73 \times
10^{-6}$, será utilizada para gerar os valores dos resíduos ($e_i = L_i -
\widehat{L_i}$) que compõem a entrada das redes de detecção.

% ------------------------------------------------------------------------------
\subsection{Redes para detecção de falhas}
De maneira simplificada, pode-se dizer que os erros de tipo I, também conhecidos
como {\it falsos positivos}, ocorrem quando o sistema reconhece uma falha que,
na verdade, não houve, enquanto que os erros de tipo II, também conhecidos como
{\it falsos negativos}, ocorrem quando o sistema deixa de reconhecer uma falha
que aconteceu.

Dessa maneira, a escolha das melhores redes de detecção se deu a partir do
número de incidência de cada um desses erros. Estabeleceu-se portanto que a
melhor rede para uma determinada falha seria aquela em que a soma dos erros de
tipo I com os erros de tipo II fosse a menor possível.

Os resultados obtidos para cada uma das falhas podem ser observados da Tab.
\ref{tab:fsedg} a Tab. \ref{tab:fsieos}. A última coluna de cada uma dessas
tabelas representa o percentual de erro total\footnote{O percentual de erro
total é obtido a partir da soma da quantidade de erros de tipo I com os erros de
tipo II, dividido pelo número total de amostras.} sobre todas as amostras. Assim
como na proposta de identificação, as melhores redes estão destacadas em cinza.

% ------------------------------------------------------------------------------
\section{Detecções}
Tendo selecionado a melhor rede de identificação do modelo e as melhores redes
de detecção, pode-se então compor o sistema final conforme Fig.
\ref{fig:composicao}.

% ------------------------------------------------------------------------------
% TODO Dissertação
% \section{Comparação das propostas de detecção}

% Falhas nos sensores ..........................................................
\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fsedg}
\vspace{1cm}
\caption{FSeDG (80\%)}
\label{fig:fsedg}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fsedo}
\vspace{1cm}
\caption{FSeDO (-2 cm)}
\label{fig:fsedo}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fsesr}
\vspace{1cm}
\caption{FSeSR ($\pm 2\%$)}
\label{fig:fsesr}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fseq}
\vspace{1cm}
\caption{FSeQ (Ganho = 0)}
\label{fig:fseq}
\end{figure}

% Falhas nos atuadores .........................................................
\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fadg}
\vspace{1cm}
\caption{FADG (80\%)}
\label{fig:fadg}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fado}
\vspace{1cm}
\caption{FADO (-0,5 Volts)}
\label{fig:fado}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fasr}
\vspace{1cm}
\caption{FASR ($\pm 2\%$)}
\label{fig:fasr}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/favk}
\vspace{1cm}
\caption{FAVK (75\%)}
\label{fig:favk}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/faq}
\vspace{1cm}
\caption{FAQ (Ganho = 0)}
\label{fig:faq}
\end{figure}

% Falhas no sistema ............................................................
\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fsivzt}
\vspace{1cm}
\caption{FSiVzT ($a_{\tiny VZ} = \frac{a_{\tiny MED}}{2}$)}
\label{fig:fsivzt}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fsivros}
\vspace{1cm}
\caption{FSiVrOS ($a' = \frac{a_{\tiny MED}}{2}$)}
\label{fig:fsivros}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fsivrgmp}
\vspace{1cm}
\caption{FSiVrGMP (90\%)}
\label{fig:fsivrgmp}
\end{figure}

\begin{figure}[htb]
\footnotesize
\centering
\input{scripts/fsieos}
\vspace{1cm}
\caption{FSiEOS (25\%)}
\label{fig:fsieos}
\end{figure}
